---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---


#following procedure from here: 
#https://www.r-bloggers.com/building-wordclouds-in-r/
```{r}
library(tm)
library(SnowballC)
library(wordcloud)
library(rvest)
library(RColorBrewer)

```

```{r retrieve-SOTU-transcript}

url<-"https://news.yahoo.com/full-text-president-trumps-2019-state-union-address-020849675.html?soc_src=hl-viewer&soc_trk=tw"

#inspecting page, first paragraph is 3 and last is 261
paras<-3:261
page<-url%>%read_html
sotu<-""
for(para in paras){
  temp<-page%>%
    html_nodes(xpath=paste0('//*[@id="Col1-0-ContentCanvas"]/article/div/p[',para,']'))%>%
    html_text()
  temp2<-page%>%
    html_nodes(xpath='//*[@id="tgt1-Col1-0-ContentCanvas"]/article/div/div[2]')%>%
    html_nodes(xpath=paste0('//*[@id="tgt1-Col1-0-ContentCanvas"]/article/div/p[',para,']'))%>%
    html_text()
  sotu<-paste(sotu,temp,temp2,sep=" ")

             }
sotu
```


```{r}

test<-page%>%html_nodes(xpath=paste0(
  '//*[@id="tgt1-Col1-0-ContentCanvas"]/article/div/div[2]/p[1]'
))

```


```{r process-into-corpus}
sotuCorpus<-Corpus(VectorSource(sotu))
sotuCorpus<-tm_map(sotuCorpus,PlainTextDocument)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))

#remove punctuation and stopwords
v<-sotuCorpus%>%
  tm_map(removeWords,stopwords('english'))%>%
  #tm_map(toSpace,'.')%>%
  tm_map(toSpace,'/')%>%
  tm_map(toSpace,'-')%>%
  tm_map(removePunctuation)%>%
  tm_map(content_transformer(tolower))%>%
  #tm_map(stemDocument)%>%
  tm_map(stripWhitespace)%>%
  TermDocumentMatrix()%>%
  as.matrix()%>%rowSums%>%sort(decreasing=TRUE)

d<-data.frame(word = names(v),freq=v)
wordcloud(words=d$word,freq=d$freq,max.words=500,random.order=FALSE,min.freq=1,
          colors=brewer.pal(8,"Dark2"))

```

```{r}

no_punc<-sotuCorpus%>%tm_map(removePunctuation)
no_punc$content$content
```